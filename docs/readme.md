# LMT Dimensionality Reduction Analysis Toolkit

A specialized Python-based pipeline for behavioral identity analysis using LDA/PCA, designed to analyze LMT (Live Mouse Tracker) datasets for discovering features and differences in mice behavior across freely-interacting groups.

> ðŸ“š **New to this toolkit?** Check out our [Setup Guide](../SETUP_GUIDE.md) for detailed installation and getting started instructions!

## Overview

This toolkit was developed to work with data generated by the Live Mouse Tracker project, providing advanced analysis capabilities for behavioral data. While originally designed for LMT datasets, the underlying techniques and methodologies can be adapted for other types of behavioral data with appropriate modifications.

Currently supports baseline analysis with three temporal resolutions:
- 12-hour intervals (night cycle)
- 4-hour chunks (circadian phases)
- Hourly resolution

## Key Features

- Dimensionality reduction techniques optimized for behavioral data
- Analysis tools for identifying behavioral patterns
- Statistical analysis capabilities for group comparisons
- Visualization tools for reduced dimensional representations
- Parallel processing support for large datasets
- Multiple temporal resolution support
- Interactive visualization capabilities

## Prerequisites
- Python 3.8+ with packages: pandas, numpy, scipy, scikit-learn, sqlite3, tkinter
- SQLite databases containing raw event/animal data
- DB Browser for SQLite (recommended for manual checks)

## Installation

The installation requires a specific order due to dependencies:

```bash
# 1. Install numpy first
pip install numpy==1.23.5

# 2. Install scipy before scikit-learn
pip install scipy>=1.9.0

# 3. Install remaining packages
pip install -r requirements.txt
```

## Project Structure

```
.
â”œâ”€â”€ data/                          # Data and visualization outputs
â”‚   â””â”€â”€ behavior_stats_intervals_analyzed/  # Interactive HTML visualizations
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ analysis/                  # Analysis scripts
â”‚   â”œâ”€â”€ behavior/                  # Behavior processing modules
â”‚   â”œâ”€â”€ preprocessing/             # Data preprocessing tools
â”‚   â”œâ”€â”€ visualization/             # Visualization utilities
â”‚   â””â”€â”€ utils/                     # Utility functions
â”œâ”€â”€ docs/                          # Documentation
â””â”€â”€ tools/                         # Utility scripts
```

## Pipeline Workflow

### 1. Event Filtering
Script: `src/preprocessing/event_filtered.py`

Purpose: Create cleaned event data with timestamps.

```python
from src.preprocessing.event_filtered import create_event_filtered_table, process_events

# The script will show a GUI for:
# 1. Database selection
# 2. Experiment start time selection

# It automatically:
# - Creates EVENT_FILTERED table
# - Excludes non-behavioral events (e.g., RFID errors, brief detections)
# - Merges adjacent events (<1 sec apart)
# - Adds duration and timestamp information
```

### 2. Behavioral Feature Extraction

Choose processor based on temporal resolution:

| Script | Resolution | Use Case | Output Tables |
|--------|------------|----------|---------------|
| behavior_processor.py | Per-experiment | Daily totals | BEHAVIOR_STATS, MULTI_MOUSE_EVENTS |
| behavior_processor_interval.py | 12h intervals (7PM-7AM) | Night-cycle analysis | behavior_stats_intervals |
| behavior_processor_hourly.py | Hourly chunks | Flexible temporal analysis | behavior_hourly, group_events_hourly |

Example usage:
```python
# Daily Totals
from src.behavior.behavior_processor import BehaviorProcessor
processor = BehaviorProcessor(db_path)
processor.process_events()

# 12-hour Intervals (Night Cycle)
from src.behavior.behavior_processor_interval import IntervalBehaviorProcessor
processor = IntervalBehaviorProcessor(db_path)
processor.process_intervals()

# Hourly Analysis
from src.behavior.behavior_processor_hourly import HourlyBehaviorProcessor
processor = HourlyBehaviorProcessor(db_path)
processor.process_hourly()
```

Key Features:
- Separates dyadic interactions into active/passive counts
- Tracks group behaviors (â‰¥3 mice)
- Imputes missing data using mouse-specific medians

### 3. Database Unification
Script: `src/database/lda_database_creator.py`

Purpose: Merge multiple experiments into one analysis-ready dataset.

Steps:
- Select source databases (GUI)
- Choose output path

Output:
- Merged SQLite database
- Corresponding CSV file

Tip: Create separate merged DBs for different temporal resolutions

# Complete Behavior Statistics Table Column Structure

## ðŸ”‘ Primary Keys
- `mouse_id` (INTEGER)
- `date` (TEXT) - Format: 'YYYY-MM-DD'

## ðŸ¤ Social Behaviors (Pairwise)

### Approach & Social Approach
- `approach_active_count`
- `approach_passive_count`
- `approach_total_duration`
- `approach_mean_duration`
- `approach_median_duration`
- `approach_std_duration`

- `social_approach_active_count`
- `social_approach_passive_count`
- `social_approach_total_duration`
- `social_approach_mean_duration`
- `social_approach_median_duration`
- `social_approach_std_duration`

### Investigation
- `oral_genital_contact_active_count`
- `oral_genital_contact_passive_count`
- `oral_genital_contact_total_duration`
- `oral_genital_contact_mean_duration`
- `oral_genital_contact_median_duration`
- `oral_genital_contact_std_duration`

- `oral_oral_contact_active_count`
- `oral_oral_contact_passive_count`
- `oral_oral_contact_total_duration`
- `oral_oral_contact_mean_duration`
- `oral_oral_contact_median_duration`
- `oral_oral_contact_std_duration`

### Contact & Movement
- `contact_active_count`
- `contact_passive_count`
- `contact_total_duration`
- `contact_mean_duration`
- `contact_median_duration`
- `contact_std_duration`

- `move_in_contact_active_count`
- `move_in_contact_passive_count`
- `move_in_contact_total_duration`
- `move_in_contact_mean_duration`
- `move_in_contact_median_duration`
- `move_in_contact_std_duration`

- `stop_in_contact_active_count`
- `stop_in_contact_passive_count`
- `stop_in_contact_total_duration`
- `stop_in_contact_mean_duration`
- `stop_in_contact_median_duration`
- `stop_in_contact_std_duration`

### Social Response/Avoidance
- `social_escape_active_count`
- `social_escape_passive_count`
- `social_escape_total_duration`
- `social_escape_mean_duration`
- `social_escape_median_duration`
- `social_escape_std_duration`

- `get_away_active_count`
- `get_away_passive_count`
- `get_away_total_duration`
- `get_away_mean_duration`
- `get_away_median_duration`
- `get_away_std_duration`

## ðŸš¶ Individual Behaviors

### Exploration & Movement
- `rearing_count`
- `rearing_total_duration`
- `rearing_mean_duration`
- `rearing_median_duration`
- `rearing_std_duration`

- `rear_in_centerwindow_count`
- `rear_in_centerwindow_total_duration`
- `rear_in_centerwindow_mean_duration`
- `rear_in_centerwindow_median_duration`
- `rear_in_centerwindow_std_duration`

- `rear_at_periphery_count`
- `rear_at_periphery_total_duration`
- `rear_at_periphery_mean_duration`
- `rear_at_periphery_median_duration`
- `rear_at_periphery_std_duration`

### Zone Occupation
- `center_zone_count`
- `center_zone_total_duration`
- `center_zone_mean_duration`
- `center_zone_median_duration`
- `center_zone_std_duration`

- `periphery_zone_count`
- `periphery_zone_total_duration`
- `periphery_zone_mean_duration`
- `periphery_zone_median_duration`
- `periphery_zone_std_duration`

### Anxiety-Related
- `walljump_count`
- `walljump_total_duration`
- `walljump_mean_duration`
- `walljump_median_duration`
- `walljump_std_duration`

- `sap_count` (Stretched Attend Posture)
- `sap_total_duration`
- `sap_mean_duration`
- `sap_median_duration`
- `sap_std_duration`

- `huddling_count`
- `huddling_total_duration`
- `huddling_mean_duration`
- `huddling_median_duration`
- `huddling_std_duration`

### Isolation
- `isolated_count`
- `isolated_total_duration`
- `isolated_mean_duration`
- `isolated_median_duration`
- `isolated_std_duration`

### Movement (Solo)
- `move_isolated_count`
- `move_isolated_total_duration`
- `move_isolated_mean_duration`
- `move_isolated_median_duration`
- `move_isolated_std_duration`

## ðŸ“Š Column Properties
- Count columns: INTEGER, default 0
- Duration columns: REAL, default 0
- Time columns: TEXT
- ID columns: INTEGER

## ðŸ” Important Notes
1. All behavior names are sanitized:
   - Spaces/hyphens â†’ underscores
   - Special characters removed
   - Non-alpha first characters prefixed with 'b_'

2. Social behaviors have:
   - Active/passive distinction
   - Separate count columns for initiator/receiver
   - Shared duration statistics

3. Duration statistics for each behavior:
   - Total duration (sum)
   - Mean duration (average)
   - Median duration (middle value)
   - Standard deviation (variability)

4. Weights in calculations:
   - Social_approach: 2.5
   - Approach: 2.0
   - Oral_genital_Contact: 3.0
   - Oral_oral_Contact: 2.8
   - Contact: 1.5
   - Move_in_contact: 1.2
   - Stop_in_contact: 1.3
   - Social_escape: 2.0
   - Get_away: 1.8

### 4. Feature Ratios
Script: `src/preprocessing/feature_ratios.py`

Purpose: Calculate social behavior metrics including initiative ratios and engagement intensities.

Example usage:
```python
from src.preprocessing.feature_ratios import calculate_ratios

# Calculate ratios for social behaviors
ratios_df = calculate_ratios(df)
```

Output:
- `ratios_df`: DataFrame with calculated ratios

### 5. Dimensionality Reduction Analysis

| Script | Method | Temporal Resolution | Key Features |
|--------|--------|-------------------|--------------|
| analysis_demo.py | LDA | 12h intervals | Identity domain stability scoring |

| analysis_demo_4h.py | LDA | 4h chunks | Circadian phase analysis |

| analysis_demo_pca.py | PCA | 4h chunks | 3D feature space projection |

Example usage:
```python
# LDA Analysis
from src.analysis.analysis_demo import run_analysis

# PCA Analysis
from src.analysis.analysis_demo_pca import run_pca_analysis
```

The analysis includes:
- Feature preprocessing
- Variance thresholding
- Correlation filtering (>0.95 correlated features removed)
- Standardization (Z-score normalization)

### 6. Visualization

The package includes interactive visualization capabilities:

```python
from src.visualization.identity_space_plotter import plot_identity_space


# Creates interactive HTML visualizations
# Output location: data/behavior_stats_(resolution)_analyzed/
```

Visualization outputs can be found in:
- `data/behavior_stats_(resolution)_analyzed/*.html`
- Open these files in any web browser to view interactive plots

## Key Script Utilities
- `id_update.py`: Safely modify mouse IDs across tables
- `database_utils.py`: DB backup/verification functions
- `db_selector.py`: GUI-based database selection

## Best Practices
- Backup databases before running processors
- Validate outputs using DB Browser
- For 4h analysis: Use merged_for_lda_hourly.csv
- For 12h analysis: Use merged_for_lda_intervals.csv

## Configuration

The package can be configured using environment variables:
- `LMT_ENV`: Set environment (development/production)
- `LMT_DEBUG`: Enable/disable debug mode

## Recent Updates

### Project Organization
- Added dedicated `tools` directory for utility scripts:
  - `fix_encoding.py`: Tool for fixing file encodings to UTF-8
- Consolidated all configuration files in `docs` folder

### New Dependencies
Added support for:
- `scipy>=1.9.0`: Linear algebra operations for analysis
- `scikit-learn>=1.0.0`: PCA and preprocessing functionality
- `plotly>=5.13.0`: Advanced visualization capabilities
- `tkcalendar>=1.6.1`: Enhanced date selection UI
- `seaborn>=0.12.2`: Statistical data visualization

### Encoding Management
- Added UTF-8 encoding support across all source files
- Implemented automatic encoding detection and conversion
- Fixed potential encoding-related issues in data processing

## License

This project is licensed under the GNU General Public License v3.0 - see the [LICENSE](LICENSE) file for details.

This means:
- You can freely use, modify, and distribute this software
- Any modifications or derivative works must also be released under the GPL v3
- You must include the original copyright notice and license
- Source code must be made available when distributing the software

## Integration with LMT Project

This toolkit is designed as a complementary analysis tool for the LMT (Live Mouse Tracker) project. While it operates as an independent toolkit, it is optimized for processing and analyzing data generated by LMT. The relationship with the main LMT project is as follows:

- Input Data: The toolkit expects data in the format generated by LMT
- Analysis Focus: Specialized in behavioral pattern analysis and dimensionality reduction
- Independence: Can be used independently or as part of the LMT workflow
- Adaptability: Can be modified to work with other behavioral data sources

## Contact

For support, contributions, or inquiries, please contact:
Andrea Stivala (andreastivala.as@gmail.com)

## Citation

If you use this toolkit in your research, please cite:
Andrea Stivala, 2025

## Acknowledgments

- Live Mouse Tracker project for inspiring this toolkit
- Contributors and maintainers of the core Python packages used in this project
- Forkosh et al. 2019 for the original dimensionality reduction pipeline this project is based on